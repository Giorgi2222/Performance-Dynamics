{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83f2683c",
   "metadata": {},
   "source": [
    "### First, we start by importing useful libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb8611f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date    datetime    dateweek  player_id  current_club_id  \\\n",
      "0  2013-08-07  2013-08-07  2013-08-05      99946             1095   \n",
      "1  2014-01-13  2014-01-13  2014-01-13      99946             1095   \n",
      "2  2010-01-29  2010-01-29  2010-01-25      76948              979   \n",
      "3  2010-08-20  2010-08-20  2010-08-16      76948              979   \n",
      "4  2011-01-17  2011-01-17  2011-01-17      76948              979   \n",
      "\n",
      "   market_value_in_eur player_club_domestic_competition_id  \n",
      "0               150000                                 FR1  \n",
      "1               100000                                 FR1  \n",
      "2               125000                                 PO1  \n",
      "3               250000                                 PO1  \n",
      "4               350000                                 PO1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read CSV file\n",
    "data = pd.read_csv('player_valuations.csv')\n",
    "\n",
    "# Print first 5 rows of data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eead1025",
   "metadata": {},
   "source": [
    "### Next, we convert data to a more convenient form for future analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f697aec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giorgi\\AppData\\Local\\Temp\\ipykernel_13360\\1449010294.py:11: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for group_id, group_data in grouped_data:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  player_id  year     price\n",
      "0        10  2004   7000000\n",
      "1        10  2005   9000000\n",
      "2        10  2006  20000000\n",
      "3        10  2007  23000000\n",
      "4        10  2008  20000000\n"
     ]
    }
   ],
   "source": [
    "# Convert date column to datetime format\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Create an empty DataFrame to store the new data\n",
    "new_data = pd.DataFrame(columns=['player_id', 'year', 'price'])\n",
    "\n",
    "# Group data by player ID\n",
    "grouped_data = data.groupby(['player_id'])\n",
    "\n",
    "# Loop over each group of data\n",
    "for group_id, group_data in grouped_data:\n",
    "\n",
    "    # Sort data by date\n",
    "    group_data = group_data.sort_values(by='date')\n",
    "    \n",
    "    # Get the minimum and maximum years for the player\n",
    "    min_year = group_data['date'].dt.year.min()\n",
    "    max_year = group_data['date'].dt.year.max()\n",
    "    \n",
    "    # Loop over each year for the player\n",
    "    for year in range(min_year, max_year+1):\n",
    "        \n",
    "        # Get the price for the year\n",
    "        try:\n",
    "            price = group_data[group_data['date'].dt.year == year]['market_value_in_eur'].values[0]\n",
    "        except IndexError:\n",
    "            price = None\n",
    "        \n",
    "        # Add a new row to the new DataFrame\n",
    "        new_row = {'player_id': group_id,\n",
    "                   'year': year,\n",
    "                   'price': price}\n",
    "        \n",
    "        # Convert the dictionary to a DataFrame\n",
    "        new_row_df = pd.DataFrame([new_row])\n",
    "\n",
    "        # Concatenate the new row to the new_data DataFrame\n",
    "        new_data = pd.concat([new_data, new_row_df], ignore_index=True)\n",
    "        \n",
    "# Print the new DataFrame\n",
    "print(new_data.head())\n",
    "\n",
    "# Save new DataFrame\n",
    "new_data.to_csv('new_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e944de0",
   "metadata": {},
   "source": [
    "### Now we will extract birth year data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a3d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load information about players to get their birth years\n",
    "player_data = pd.read_csv('players.csv')\n",
    "\n",
    "# Convert date column to datetime format\n",
    "player_data['date_of_birth'] = pd.to_datetime(player_data['date_of_birth'])\n",
    "# Extract player IDs and birth years\n",
    "ids = []\n",
    "birth_years = []\n",
    "for index, row in player_data.iterrows():\n",
    "    player_id = row['player_id']\n",
    "    birth_year = row['date_of_birth'].year\n",
    "    if player_id not in ids and birth_year != None:\n",
    "        ids.append(player_id)\n",
    "        birth_years.append(birth_year)\n",
    "\n",
    "# Create a new DataFrame with the extracted data\n",
    "birth_years = pd.DataFrame({'player_id': ids, 'birth_year': birth_years})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5278f436",
   "metadata": {},
   "source": [
    "### Using birth year data we group data points by the ages of players at the time of measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f65e76be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load new_data DataFrame\n",
    "df =  pd.read_csv('new_data.csv')\n",
    "temp = np.arange(10, 50)\n",
    "\n",
    "# Create dictionary to store prices for each age group\n",
    "ages = {i: [] for i in temp}\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    age = row['year'] - birth_years.loc[birth_years['player_id'] == row['player_id'], 'birth_year'].values[0]\n",
    "    if age in temp and row['price'] > 0:\n",
    "        ages[age].append(row['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34d9ca7",
   "metadata": {},
   "source": [
    "### We finish preparing data by computing percentiles and dividing data into features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbffc9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import percentileofscore\n",
    "\n",
    "# Add a 'percentile' column to the dataframe, which will be populated with percentiles computed based on the player's age and price\n",
    "df['percentile'] = ''\n",
    "\n",
    "# Iterate over each row in the dataframe\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    # Compute the player's age by subtracting their birth year from the year in which the valuation was made\n",
    "    age = row['year'] - birth_years.loc[birth_years['player_id'] == row['player_id'], 'birth_year'].values[0]\n",
    "    \n",
    "    # Check if the player's age is in the set of ages for which we have computed percentiles, and if the player's price is positive\n",
    "    if age in temp and row['price'] > 0:  \n",
    "        \n",
    "        # Compute the percentile of the player's price based on their age\n",
    "        df.loc[index, 'percentile'] = percentileofscore(ages[age], row['price'])\n",
    "\n",
    "# Write the dataframe to a CSV file\n",
    "df.to_csv('percentiles.csv', index=False)\n",
    "\n",
    "# Read the percentiles CSV file back into a new dataframe\n",
    "df = pd.read_csv('percentiles.csv')\n",
    "\n",
    "# Initialize two numpy arrays to store the input and output for the LSTM model\n",
    "x = np.empty((0, 4))\n",
    "y = np.empty((0, 1))\n",
    "\n",
    "# Initialize variables to keep track of the player ID and the number of percentiles seen so far for the current player\n",
    "id_ = df.iloc[0]['player_id']\n",
    "count = 0 \n",
    "\n",
    "# Initialize a numpy array to store the most recent 5 percentiles for the current player\n",
    "short_list = np.zeros(5)\n",
    "\n",
    "# Iterate over each row in the dataframe\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    # If the current row corresponds to the same player as the previous row, and we have not yet seen 5 percentiles for the player, and the percentile is not missing\n",
    "    if id_ == row['player_id'] and count < 5 and row['percentile']:\n",
    "        \n",
    "        # Add the percentile to the short_list\n",
    "        short_list[count] = row['percentile']\n",
    "        count += 1\n",
    "    \n",
    "    # If we have seen 5 percentiles for the current player, and they are all positive\n",
    "    elif count == 5 and np.all(short_list > 0):\n",
    "        \n",
    "        # Append the first 4 percentiles to x, and the 5th percentile to y\n",
    "        x = np.vstack([x, [short_list[0], short_list[1], short_list[2], short_list[3]]])\n",
    "        y = np.vstack([y, [short_list[4]]])\n",
    "        \n",
    "        # Reset the count and short_list for the next player\n",
    "        count = 0 \n",
    "        id_ = row['player_id']\n",
    "    \n",
    "    # If the current row corresponds to a new player, or we have not yet seen 5 positive percentiles for the current player\n",
    "    else:\n",
    "        \n",
    "        # Reset the count and ID for the new player\n",
    "        id_ = row['player_id']\n",
    "        count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d617b9",
   "metadata": {},
   "source": [
    "### Next, we can calculate what percentage of players who decline for three years, start growing on fourth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "161b91fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.27\n"
     ]
    }
   ],
   "source": [
    "# Initialize count and negative count variables\n",
    "count = 0\n",
    "negative_count = 0\n",
    "\n",
    "# Loop through each row of x\n",
    "for i in range(len(x)):\n",
    "    \n",
    "    # Check if the difference between adjacent years in the row of x are negative\n",
    "    if x[i, 1] - x[i, 0] < 0 and x[i, 2] - x[i, 1] < 0 and x[i, 3] - x[i, 2] < 0:\n",
    "        \n",
    "        # Increment count variable\n",
    "        count += 1\n",
    "        \n",
    "        # Check if corresponding element in y is negative\n",
    "        if y[i] - x[i, 3] < 0:\n",
    "            \n",
    "            # Increment negative_count variable\n",
    "            negative_count += 1\n",
    "\n",
    "# Calculate percentage of cases where y - x[i,3] is negative, given that the differences between adjacent elements in the row are all negative\n",
    "percentage = (1 - negative_count/ count) * 100\n",
    "\n",
    "# Print percentage\n",
    "print(\"%.2f\" % percentage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef43e72",
   "metadata": {},
   "source": [
    "### Finally, we train the machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc427ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "410/410 [==============================] - 8s 8ms/step - loss: 2193.6633 - val_loss: 1343.2115\n",
      "Epoch 2/20\n",
      "410/410 [==============================] - 3s 7ms/step - loss: 967.3699 - val_loss: 655.4146\n",
      "Epoch 3/20\n",
      "410/410 [==============================] - 3s 7ms/step - loss: 496.8141 - val_loss: 362.7880\n",
      "Epoch 4/20\n",
      "410/410 [==============================] - 3s 8ms/step - loss: 290.4272 - val_loss: 230.6130\n",
      "Epoch 5/20\n",
      "410/410 [==============================] - 3s 7ms/step - loss: 196.8273 - val_loss: 170.4215\n",
      "Epoch 6/20\n",
      "410/410 [==============================] - 3s 7ms/step - loss: 153.3793 - val_loss: 139.3420\n",
      "Epoch 7/20\n",
      "410/410 [==============================] - 3s 6ms/step - loss: 132.4875 - val_loss: 125.4251\n",
      "Epoch 8/20\n",
      "410/410 [==============================] - 3s 8ms/step - loss: 121.7476 - val_loss: 116.7512\n",
      "Epoch 9/20\n",
      "410/410 [==============================] - 3s 8ms/step - loss: 116.3822 - val_loss: 114.3287\n",
      "Epoch 10/20\n",
      "410/410 [==============================] - 3s 7ms/step - loss: 113.6656 - val_loss: 111.0508\n",
      "Epoch 11/20\n",
      "410/410 [==============================] - 3s 7ms/step - loss: 112.0013 - val_loss: 111.2272\n",
      "Epoch 12/20\n",
      "410/410 [==============================] - 3s 6ms/step - loss: 111.3920 - val_loss: 110.4977\n",
      "Epoch 13/20\n",
      "410/410 [==============================] - 3s 7ms/step - loss: 110.7124 - val_loss: 109.7419\n",
      "Epoch 14/20\n",
      "410/410 [==============================] - 3s 7ms/step - loss: 110.1758 - val_loss: 111.4721\n",
      "Epoch 15/20\n",
      "410/410 [==============================] - 3s 7ms/step - loss: 110.0980 - val_loss: 112.9049\n",
      "Epoch 16/20\n",
      "410/410 [==============================] - 3s 8ms/step - loss: 110.3014 - val_loss: 109.1833\n",
      "Epoch 17/20\n",
      "410/410 [==============================] - 3s 6ms/step - loss: 109.7484 - val_loss: 109.5988\n",
      "Epoch 18/20\n",
      "410/410 [==============================] - 3s 6ms/step - loss: 109.5375 - val_loss: 111.3901\n",
      "Epoch 19/20\n",
      "410/410 [==============================] - 3s 7ms/step - loss: 109.6131 - val_loss: 110.2936\n",
      "Epoch 20/20\n",
      "410/410 [==============================] - 3s 8ms/step - loss: 109.8326 - val_loss: 109.2337\n",
      "114/114 [==============================] - 2s 3ms/step\n",
      "110.99207690507863\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "\n",
    "# Split training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data to include a third dimension for the features\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Define the LSTM model architecture\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict the fifth state using the trained model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(np.mean((y_test - y_pred)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cce1c2e",
   "metadata": {},
   "source": [
    "### Now we can predict players' future percentile ranking based on data from the last 4 years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2238c394",
   "metadata": {},
   "source": [
    "#### Prediction for failed transfers of the past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abad43bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last four years:  [[79.39946416 71.66619975 70.09111617 43.49641009]]\n",
      "Prediction for the season with Dinamo Batumi:         [[38.18688]]\n",
      "\n",
      "Last four years:  [[79.39946416 44.95377504 40.44419134 36.1245617 ]]\n",
      "Prediction for the season with Dinamo Batumi:         [[33.0647]]\n",
      "\n",
      "Last four years:  [[27.77559956 40.00560303 51.42748671 29.08665887]]\n",
      "Prediction for the season with Dinamo Batumi:         [[26.618525]]\n"
     ]
    }
   ],
   "source": [
    "# https://www.transfermarkt.com/godfrey-oboabona/profil/spieler/217656\n",
    "x_Oboabona = np.array([[percentileofscore(ages[25], 2500000), percentileofscore(ages[26], 1800000), percentileofscore(ages[27], 1800000), percentileofscore(ages[28], 650000)]]).reshape(1, X_train.shape[1], 1)  \n",
    "print(\"Last four years: \", x_Oboabona.reshape(1, -1))\n",
    "print(\"Prediction for the season with Dinamo Batumi:        \", model.predict(x_Oboabona, verbose=0))\n",
    "print()\n",
    "# https://www.transfermarkt.com/abraham-frimpong/profil/spieler/189402\n",
    "x_Frimpong = np.array([[percentileofscore(ages[25], 2500000), percentileofscore(ages[26], 600000), percentileofscore(ages[27], 550000), percentileofscore(ages[28], 500000)]]).reshape(1, X_train.shape[1], 1)  \n",
    "print(\"Last four years: \", x_Frimpong.reshape(1, -1))\n",
    "print(\"Prediction for the season with Dinamo Batumi:        \", model.predict(x_Frimpong, verbose=0))\n",
    "print()\n",
    "# https://www.transfermarkt.com/lukas-grozurek/profil/spieler/75829\n",
    "x_Grozurek = np.array([[percentileofscore(ages[25], 300000), percentileofscore(ages[26], 500000), percentileofscore(ages[27], 800000), percentileofscore(ages[28], 400000)]]).reshape(1, X_train.shape[1], 1)  \n",
    "print(\"Last four years: \", x_Grozurek.reshape(1, -1))\n",
    "print(\"Prediction for the season with Dinamo Batumi:        \", model.predict(x_Grozurek, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf9c66b",
   "metadata": {},
   "source": [
    "#### Prediction for the new Dinamo Batumi player for the current season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7f42764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last four years:  [[90.88457767 84.22551253 75.75972616 60.63432836]]\n",
      "Prediction for the season with Dinamo Batumi:         [[53.063496]]\n"
     ]
    }
   ],
   "source": [
    "# https://www.transfermarkt.com/moussa-konate/profil/spieler/192774\n",
    "x_Konaté = np.array([[percentileofscore(ages[26], 7000000), percentileofscore(ages[27], 4000000), percentileofscore(ages[28], 2500000), percentileofscore(ages[29], 1200000)]]).reshape(1, X_train.shape[1], 1)    \n",
    "print(\"Last four years: \", x_Konaté.reshape(1, -1))\n",
    "print(\"Prediction for the season with Dinamo Batumi:        \", model.predict(x_Konaté, verbose=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
